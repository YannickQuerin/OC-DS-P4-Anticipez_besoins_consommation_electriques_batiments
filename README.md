# Anticiper les besoins en consommation √©lectrique des b√¢timents

## üìã Description du projet

Ce projet vise √† r√©pondre √† l'objectif de la ville de Seattle : **atteindre la neutralit√© carbone d'ici 2050**. Pour cela, il est n√©cessaire d'anticiper les besoins en consommation √©nerg√©tique des b√¢timents ainsi que leurs √©missions de CO2, √† partir de donn√©es r√©colt√©es en 2015 et 2016. 

### Objectifs principaux :
- **Pr√©dire** la consommation totale d'√©nergie des b√¢timents.
- **Pr√©dire** les √©missions de CO2.
- **√âvaluer** l'int√©r√™t de la variable *EnergyStarScore* dans la pr√©diction des √©missions.

---

## üìä Donn√©es utilis√©es

- Deux jeux de donn√©es (2015 et 2016), comprenant :
  - Informations sur les b√¢timents : localisation, type d'usage, caract√©ristiques physiques.
  - Consommation √©nerg√©tique.
  - √âmissions de gaz √† effet de serre (GES).

### Pr√©paration des donn√©es
- Suppression des doublons et variables inutiles.
- Traitement des valeurs manquantes et aberrantes.
- Cr√©ation de nouvelles variables (*feature engineering*).
- Transformation des variables cibles pour r√©duire la skewness (logarithmique).

![Data Processing](Illustration_diapos/problematique_P4.png)

---

## üîç Mod√©lisation

### Mod√®les explor√©s
- R√©gressions lin√©aires.
- Mod√®les d'ensemble :
  - Random Forest
  - Gradient Boosting Regressor
  - Extreme Gradient Boosting (XGBoost).

### Processus de s√©lection
- S√©paration des donn√©es :
  - 80% pour l'entra√Ænement.
  - 20% pour le test.
- Validation crois√©e (k-fold).
- Optimisation des hyperparam√®tres :
  - *RandomizedSearchCV*
  - *GridSearchCV*

### R√©sultats
- **Mod√®le final : Gradient Boosting Regressor**
  - Pr√©diction de la consommation √©nerg√©tique :
    - R¬≤ : 0,91
    - RMSE : 0,872
  - Pr√©diction des √©missions de CO2 :
    - R¬≤ : 0,91
    - RMSE : 0,408

![Model Performance](Illustration_diapos/resultats_rnd_search_conso_energie.png)
![Model Performance](Illustration_diapos/resultats_grid_search_conso_energie.png)
![Model Performance](Illustration_diapos/res_graphique_modelisation_conso.png)
![Model Performance](Illustration_diapos/resultats_rnd_search_emissions.png)
![Model Performance](Illustration_diapos/resultats_grid_search_emissions.png)
![Model Performance](Illustration_diapos/res_graphique_modelisation_emissions.png)

### Analyse de l'EnergyStarScore

![Analyse_EnergyScore](Illustration_diapos/interet_variable_energy_score.png)
![Analyse_EnergyScore](Illustration_diapos/interet_variable_energy_score1.png)

- L'inclusion de la variable *EnergyStarScore* n'am√©liore pas significativement les performances pr√©dictives, mais elle peut √™tre utilis√©e selon les besoins m√©tiers.

---

## üìà R√©sultats et visualisations

### Importance des caract√©ristiques
![Feature Importance](Illustration_diapos/features_importance_conso.png)
![Feature Importance](Illustration_diapos/features_importance_emissions.png)


- Les variables les plus importantes pour la pr√©diction :
  - Localisation des b√¢timents.
  - Type d'√©nergie utilis√©e.
  - Surface totale.

### Pr√©dictions
![Predictions](Illustration_diapos/predictions_conso.png)
![Predictions](Illustration_diapos/predictions_emissions.png)

---

## üöÄ Perspectives

### Am√©liorations possibles
1. **Enrichissement des donn√©es** :
   - Collecte de donn√©es suppl√©mentaires via des sources publiques ou des API.
   - Ajout de variables li√©es aux √©nergies renouvelables.
2. **Optimisation des mod√®les** :
   - Exploration de r√©seaux de neurones pour la pr√©diction.
   - R√©duction du nombre de composantes via des techniques de r√©duction de dimensions (PCA).

---

## üõ†Ô∏è Technologies utilis√©es

- **Langages** : Python (Pandas, NumPy, Scikit-learn, PyCaret).
- **Outils de visualisation** : Matplotlib, Seaborn.
- **Machine Learning** : XGBoost, Gradient Boosting, Random Forest.
- **Pipeline de donn√©es** : Nettoyage, Feature Engineering, Mod√©lisation.


